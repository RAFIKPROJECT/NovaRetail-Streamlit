import io
import json
import zipfile
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px

# =========================
# CONFIG
# =========================
st.set_page_config(page_title="NovaRetail â€” Bloc 2", page_icon="ğŸ“Š", layout="wide")

VALID_CHANNELS = ["Emailing", "Google Ads", "LinkedIn Ads"]

CHANNEL_NORMALIZATION = {
    "googleads": "Google Ads",
    "google ads": "Google Ads",
    "linkedin": "LinkedIn Ads",
    "linkedin ads": "LinkedIn Ads",
    "e-mailing": "Emailing",
    "emailing": "Emailing",
}
DEVICE_NORMALIZATION = {"desktop": "Desktop", "mobile": "Mobile", "tablet": "Tablet"}
REGION_NORMALIZATION = {"Ile-de-France": "Ãle-de-France"}
COMPANY_SIZE_NORMALIZATION = {"10 - 50": "10-50", "50- 100": "50-100"}

STATUS_RANK = {"Client": 3, "SQL": 2, "MQL": 1, "Lost": 0}

# =========================
# UTILS
# =========================
def _count_missing(df: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for c in df.columns:
        s = df[c]
        na = int(s.isna().sum())
        empty = int((s.astype(str).str.strip() == "").sum())
        rows.append({"variable": c, "missing_count": na + empty})
    out = pd.DataFrame(rows).sort_values("missing_count", ascending=False)
    return out

def norm_channel(x):
    if pd.isna(x):
        return np.nan
    s = str(x).strip()
    if not s:
        return np.nan
    return CHANNEL_NORMALIZATION.get(s.lower(), s)

def norm_device(x):
    if pd.isna(x):
        return np.nan
    s = str(x).strip()
    if not s:
        return np.nan
    return DEVICE_NORMALIZATION.get(s.lower(), s.title())

def compute_campaign_kpis_by_channel(camp_agg: pd.DataFrame) -> pd.DataFrame:
    out = camp_agg.copy()
    out["CTR"] = out["clicks"] / out["impressions"]
    out["conversion_rate"] = out["conversions"] / out["clicks"]
    out["CPL"] = out["cost"] / out["conversions"]
    return out

def freq_table(df: pd.DataFrame, col: str) -> pd.DataFrame:
    s = df[col].fillna("NA")
    out = s.value_counts(dropna=False).rename("count").to_frame()
    out["percent"] = (out["count"] / out["count"].sum()).round(4)
    return out

def crosstab_percent(df: pd.DataFrame, a: str, b: str) -> pd.DataFrame:
    return (pd.crosstab(df[a], df[b], normalize="index").fillna(0) * 100).round(1)

# =========================
# APP HEADER
# =========================
st.title("ğŸ“Š NovaRetail â€” Bloc 2 : SÃ©lection & InterprÃ©tation des DonnÃ©es (IA)")
st.caption("Upload â†’ Filtrage pÃ©rimÃ¨tre â†’ Nettoyage â†’ KPI â†’ Analyses â†’ Graphiques â†’ Dashboard â†’ Exports")

st.sidebar.header("1) Upload des fichiers")
leads_file = st.sidebar.file_uploader("leads (CSV)", type=["csv"])
camp_file = st.sidebar.file_uploader("campaigns (JSON)", type=["json"])
crm_file = st.sidebar.file_uploader("crm (XLSX)", type=["xlsx"])

st.sidebar.header("2) PÃ©rimÃ¨tre")
month = st.sidebar.selectbox("Mois (pÃ©rimÃ¨tre imposÃ©)", ["2025-10"], index=0)
channels_sel = st.sidebar.multiselect("Canaux analysÃ©s", VALID_CHANNELS, default=VALID_CHANNELS)

run = st.sidebar.button("ğŸš€ ExÃ©cuter", type="primary")

if not (leads_file and camp_file and crm_file):
    st.info("â¬…ï¸ Importer les 3 fichiers pour commencer (CSV + JSON + XLSX).")
    st.stop()

if not run and "final_df" not in st.session_state:
    st.warning("Clique sur **ExÃ©cuter**.")
    st.stop()

# =========================
# PIPELINE
# =========================
if run:
    with st.spinner("Traitement (chargement + nettoyage + KPI)..."):
        # ---- Load
        leads = pd.read_csv(leads_file)
        campaigns = pd.read_json(camp_file)
        crm = pd.read_excel(crm_file)

        # ---- Report before
        before = {
            "leads_rows": len(leads),
            "crm_rows": len(crm),
            "campaign_rows": len(campaigns),
            "missing_leads": _count_missing(leads),
            "missing_crm": _count_missing(crm),
            "missing_campaigns": _count_missing(campaigns),
        }

        # ---- Normalize / Types
        leads = leads.copy()
        crm = crm.copy()
        campaigns = campaigns.copy()

        leads["date"] = pd.to_datetime(leads["date"], errors="coerce")
        leads["channel"] = leads["channel"].apply(norm_channel)
        leads["device"] = leads["device"].apply(norm_device)

        for col in ["company_size", "sector", "region", "status"]:
            if col not in crm.columns:
                crm[col] = np.nan

        crm["company_size"] = crm["company_size"].astype(str).str.strip().replace(COMPANY_SIZE_NORMALIZATION)
        crm["company_size"] = crm["company_size"].replace({"": np.nan, "nan": np.nan})
        crm["sector"] = crm["sector"].astype(str).str.strip().replace({"": np.nan, "nan": np.nan})
        crm["region"] = crm["region"].astype(str).str.strip().replace(REGION_NORMALIZATION).replace({"": np.nan, "nan": np.nan})
        crm["status"] = crm["status"].astype(str).str.strip().replace({"": np.nan, "nan": np.nan})

        # ---- Filter scope (Oct 2025)
        month_start = pd.to_datetime(f"{month}-01")
        month_end = month_start + pd.offsets.MonthEnd(1)
        leads = leads[(leads["date"] >= month_start) & (leads["date"] <= month_end)]

        # ---- Keep valid channels + selected channels
        leads = leads[leads["channel"].isin(VALID_CHANNELS)]
        leads = leads[leads["channel"].isin(channels_sel)]

        # ---- Deduplicate leads by lead_id
        leads_before = len(leads)
        leads = leads.sort_values(["lead_id", "date"]).drop_duplicates(subset=["lead_id"], keep="first")
        dup_leads_removed = leads_before - len(leads)

        # ---- Deduplicate CRM keep best status
        crm["_rank"] = crm["status"].map(STATUS_RANK).fillna(-1)
        crm_before = len(crm)
        crm = crm.sort_values(["lead_id", "_rank"], ascending=[True, False]).drop_duplicates(subset=["lead_id"], keep="first")
        crm = crm.drop(columns=["_rank"])
        dup_crm_removed = crm_before - len(crm)

        # ---- Aggregate campaigns by channel (sum) for KPI
        camp_agg = campaigns.groupby("channel", as_index=False).agg(
            cost=("cost", "sum"),
            impressions=("impressions", "sum"),
            clicks=("clicks", "sum"),
            conversions=("conversions", "sum"),
        )
        camp_agg = camp_agg[camp_agg["channel"].isin(channels_sel)]

        # ---- Merge
        df = leads.merge(crm, on="lead_id", how="left", validate="one_to_one")
        df = df.merge(camp_agg, on="channel", how="left", validate="many_to_one")

        # ---- After report
        after = {
            "final_rows": len(df),
            "dup_leads_removed": int(dup_leads_removed),
            "dup_crm_removed": int(dup_crm_removed),
            "missing_final": _count_missing(df),
        }

        st.session_state["final_df"] = df
        st.session_state["before"] = before
        st.session_state["after"] = after
        st.session_state["camp_agg"] = camp_agg

df = st.session_state["final_df"]
before = st.session_state["before"]
after = st.session_state["after"]
camp_agg = st.session_state["camp_agg"]

# =========================
# KPI / ANALYSES
# =========================
camp_kpi = compute_campaign_kpis_by_channel(camp_agg)

total_leads = len(df)
clients = int((df["status"] == "Client").sum())
sql = int((df["status"] == "SQL").sum())
mql = int((df["status"] == "MQL").sum())
unknown = int(df["status"].isna().sum())
client_rate = (clients / total_leads) if total_leads else 0.0

best_cpl_channel = camp_kpi.sort_values("CPL").iloc[0]["channel"] if len(camp_kpi) else "â€”"
best_ctr_channel = camp_kpi.sort_values("CTR", ascending=False).iloc[0]["channel"] if len(camp_kpi) else "â€”"

# =========================
# DASHBOARD (3â€“6 KPI)
# =========================
c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric("Leads (Oct 2025)", f"{total_leads:,}".replace(",", " "))
c2.metric("Clients", f"{clients:,}".replace(",", " "))
c3.metric("% Clients", f"{client_rate*100:.1f}%")
c4.metric("SQL", f"{sql:,}".replace(",", " "))
c5.metric("Meilleur CPL", f"{camp_kpi['CPL'].min():.2f} â‚¬" if len(camp_kpi) else "â€”")
c6.metric("Canal + rentable", best_cpl_channel)

st.divider()

# =========================
# TABS
# =========================
tab1, tab2, tab3, tab4 = st.tabs([
    "1) SÃ©lection & Nettoyage (preuves)",
    "2) Analyse uni/bivariÃ©e",
    "3) Graphiques (3â€“6)",
    "4) Exports (livrables)",
])

with tab1:
    st.subheader("1) SÃ©lection des observations & variables (pÃ©rimÃ¨tre)")
    st.markdown(
        f"""
- **PÃ©rimÃ¨tre** : {month} uniquement (Octobre 2025)  
- **Canaux** : {", ".join(channels_sel)}  
- **Variables retenues (utiles mÃ©tier)** :  
  - Leads : `lead_id`, `date`, `channel`, `device` (identification + source acquisition + device)  
  - CRM : `company_size`, `sector`, `region`, `status` (segmentation + qualitÃ© lead)  
  - Campagnes : `cost`, `impressions`, `clicks`, `conversions` (KPI CTR/Conv/CPL)  
- **Variables exclues** : non prÃ©sentes / non utiles (pas de suppressions arbitraires).
"""
    )

    st.write("### Preuves attendues â€” valeurs manquantes (avant)")
    colA, colB, colC = st.columns(3)
    with colA:
        st.caption("Leads")
        st.dataframe(before["missing_leads"], use_container_width=True, height=240)
    with colB:
        st.caption("CRM")
        st.dataframe(before["missing_crm"], use_container_width=True, height=240)
    with colC:
        st.caption("Campaigns")
        st.dataframe(before["missing_campaigns"], use_container_width=True, height=240)

    st.write("### Nettoyage appliquÃ© (rÃ©sumÃ©)")
    st.json({
        "filtrage_perimetre": month,
        "canaux_valides": VALID_CHANNELS,
        "doublons_supprimes_leads": after["dup_leads_removed"],
        "doublons_supprimes_crm": after["dup_crm_removed"],
        "normalisation": ["channel", "device", "region", "company_size"],
        "campagnes": "agrÃ©gation par canal (sommes)",
    })

    st.write("### Preuves attendues â€” valeurs manquantes (aprÃ¨s)")
    st.dataframe(after["missing_final"], use_container_width=True, height=280)

    st.write("### AperÃ§u dataset final (aprÃ¨s filtrage + fusion)")
    st.dataframe(df.head(30), use_container_width=True)

with tab2:
    st.subheader("2) Analyse univariÃ©e et bivariÃ©e")

    st.write("### Quantitatives (campagnes par canal)")
    st.dataframe(camp_kpi[["channel","cost","impressions","clicks","conversions","CTR","conversion_rate","CPL"]], use_container_width=True)

    st.write("### Qualitatives (frÃ©quences)")
    f1, f2, f3, f4 = st.columns(4)
    with f1:
        st.caption("Channel")
        st.dataframe(freq_table(df, "channel"), use_container_width=True, height=220)
    with f2:
        st.caption("Device")
        st.dataframe(freq_table(df, "device"), use_container_width=True, height=220)
    with f3:
        st.caption("Status")
        st.dataframe(freq_table(df, "status"), use_container_width=True, height=220)
    with f4:
        st.caption("Region")
        st.dataframe(freq_table(df, "region"), use_container_width=True, height=220)

    st.write("### BivariÃ©e (croisements mÃ©tier pertinents)")
    st.caption("Channel Ã— Status (% par canal) â€” qualitÃ© des leads par levier")
    st.dataframe(crosstab_percent(df, "channel", "status"), use_container_width=True)

    st.caption("Company size Ã— Status (% par taille) â€” segments les plus â€˜clientsâ€™")
    if df["company_size"].notna().any():
        st.dataframe(crosstab_percent(df, "company_size", "status"), use_container_width=True)
    else:
        st.info("company_size manquant aprÃ¨s fusion/filtrage (selon CRM).")

    st.caption("Sector Ã— Status (% par secteur)")
    if df["sector"].notna().any():
        st.dataframe(crosstab_percent(df, "sector", "status"), use_container_width=True)
    else:
        st.info("sector manquant aprÃ¨s fusion/filtrage (selon CRM).")

with tab3:
    st.subheader("3) Visualisations (5 graphiques) â€” chaque graphe rÃ©pond Ã  une question mÃ©tier")

    # 1) CTR
    fig1 = px.bar(camp_kpi, x="channel", y="CTR",
                  title="CTR par canal â€” Quel canal capte le mieux lâ€™attention ?")
    st.plotly_chart(fig1, use_container_width=True)

    # 2) CPL
    fig2 = px.bar(camp_kpi, x="channel", y="CPL",
                  title="CPL par canal â€” Quel canal est le plus rentable ?")
    st.plotly_chart(fig2, use_container_width=True)

    # 3) Conversion rate
    fig3 = px.bar(camp_kpi, x="channel", y="conversion_rate",
                  title="Taux de conversion (clic â†’ conversion) par canal â€” QualitÃ© du trafic")
    st.plotly_chart(fig3, use_container_width=True)

    # 4) Status distribution per channel
    dist = df.groupby(["channel","status"]).size().reset_index(name="count")
    fig4 = px.bar(dist, x="channel", y="count", color="status", barmode="stack",
                  title="Funnel marketing â€” RÃ©partition MQL/SQL/Client par canal")
    st.plotly_chart(fig4, use_container_width=True)

    # 5) Clients by region (if possible)
    if df["region"].notna().any():
        clients_region = (df[df["status"]=="Client"]
                          .groupby("region").size().reset_index(name="clients")
                          .sort_values("clients", ascending=False))
        fig5 = px.bar(clients_region, x="region", y="clients",
                      title="Clients par rÃ©gion â€” OÃ¹ concentrer la prospection ?")
        st.plotly_chart(fig5, use_container_width=True)

with tab4:
    st.subheader("4) Livrables â€” Exports + Note mÃ©tier + Carnet technique")

    # Note mÃ©tier (1â€“2 pages max, synthÃ©tique)
    note = f"""
# Note dâ€™analyse mÃ©tier â€” NovaRetail (Bloc 2)

## Contexte & objectifs
NovaRetail (SaaS B2B) a lancÃ© plusieurs campagnes (Emailing, Google Ads, LinkedIn Ads) et alimente un CRM.
Lâ€™objectif est de sÃ©lectionner les donnÃ©es du pÃ©rimÃ¨tre **octobre 2025**, nettoyer et fusionner les sources,
calculer des KPI marketing (**CTR**, **taux de conversion**, **CPL**), analyser la qualitÃ© des leads (MQL/SQL/Client)
et proposer des recommandations opÃ©rationnelles.

## RÃ©sultats clÃ©s
- Leads analysÃ©s (aprÃ¨s nettoyage/fusion) : **{total_leads}**
- Clients : **{clients}** (taux client : **{client_rate*100:.1f}%**)
- Meilleur CTR : **{best_ctr_channel}**
- Meilleur CPL (rentabilitÃ©) : **{best_cpl_channel}**

## InterprÃ©tation mÃ©tier
- Un canal avec un CTR Ã©levÃ© nâ€™est pas forcÃ©ment le plus rentable : le **CPL** et la part de **Clients** sont critiques.
- La distribution **MQL â†’ SQL â†’ Client** par canal indique la qualitÃ© du trafic et la performance commerciale.
- Les segmentations (taille, secteur, rÃ©gion) permettent de cibler les segments les plus convertisseurs.

## Recommandations opÃ©rationnelles
1) RÃ©allouer une partie du budget vers **{best_cpl_channel}** (meilleure rentabilitÃ©).
2) Optimiser le canal le moins rentable : ciblage, message, landing page, nurturing CRM.
3) Prioriser les segments (secteur/rÃ©gion/taille) qui prÃ©sentent la plus forte proportion de **Clients**.
4) Mettre en place un suivi hebdomadaire des KPI (dashboard) et un contrÃ´le de qualitÃ© des donnÃ©es (doublons/manquants).
""".strip()

    # Carnet technique (problÃ¨mes + solutions)
    carnet = pd.DataFrame([
        {"ProblÃ¨me":"Lignes hors pÃ©rimÃ¨tre", "Solution":"Filtrer les dates sur Octobre 2025", "Justification":"Respect consigne, comparabilitÃ© des analyses."},
        {"ProblÃ¨me":"Doublons lead_id", "Solution":"DÃ©duplication leads (1 ligne/lead) + CRM (meilleur statut)", "Justification":"Ã‰vite biais sur volumes et taux."},
        {"ProblÃ¨me":"CatÃ©gories incohÃ©rentes", "Solution":"Normalisation channel/device/region/company_size", "Justification":"AgrÃ©gations fiables (KPI & segmentations)."},
        {"ProblÃ¨me":"Valeurs manquantes", "Solution":"Conserver NA + reporting des manquants", "Justification":"TraÃ§abilitÃ©, pas de suppression globale interdite."},
        {"ProblÃ¨me":"Campagnes multiples", "Solution":"AgrÃ©gation par canal (somme des coÃ»ts/impressions/clicks/conversions)", "Justification":"KPI comparables entre canaux."},
    ])

    st.download_button("ğŸ“¥ Dataset nettoyÃ© (CSV)", df.to_csv(index=False).encode("utf-8"), "novaretail_clean.csv", "text/csv")
    st.download_button("ğŸ“¥ KPI campagnes (CSV)", camp_kpi.to_csv(index=False).encode("utf-8"), "novaretail_kpi_campaigns.csv", "text/csv")
    st.download_button("ğŸ“¥ Note mÃ©tier (MD)", note.encode("utf-8"), "novaretail_note_metier.md", "text/markdown")
    st.download_button("ğŸ“¥ Carnet technique (CSV)", carnet.to_csv(index=False).encode("utf-8"), "novaretail_carnet_technique.csv", "text/csv")

    # Export ZIP complet
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as z:
        z.writestr("exports/novaretail_clean.csv", df.to_csv(index=False))
        z.writestr("exports/novaretail_kpi_campaigns.csv", camp_kpi.to_csv(index=False))
        z.writestr("exports/novaretail_note_metier.md", note)
        z.writestr("exports/novaretail_carnet_technique.csv", carnet.to_csv(index=False))
        z.writestr("exports/rapport_qualite_avant_missing.csv", before["missing_leads"].to_csv(index=False))
        z.writestr("exports/rapport_qualite_apres_missing.csv", after["missing_final"].to_csv(index=False))
    st.download_button("ğŸ“¦ TÃ©lÃ©charger TOUS les livrables (ZIP)", buf.getvalue(), "novaretail_livrables.zip", "application/zip")

    st.write("### PrÃ©visualisation â€” Note mÃ©tier")
    st.code(note, language="markdown")

    st.write("### PrÃ©visualisation â€” Carnet technique")
    st.dataframe(carnet, use_container_width=True)
